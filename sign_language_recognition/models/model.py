import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D, BatchNormalization
# L2 ì •ê·œí™”ê°€ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ importì—ì„œ ì œê±°í•©ë‹ˆë‹¤.
# from tensorflow.keras.regularizers import l2
from sign_language_recognition.train.utils import log_message

def build_lstm_model(input_shape: tuple, num_classes: int) -> tf.keras.Model:
    """
    ì‹¤ì‹œê°„ ìˆ˜ì–´ í†µì—­ ì‹œìŠ¤í…œì— ì í•©í•œ ê²½ëŸ‰í™”ëœ Bidirectional LSTM ê¸°ë°˜ ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
    (ì»´íŒŒì¼ì€ train.pyì—ì„œ ìˆ˜í–‰í•©ë‹ˆë‹¤.)

    Args:
        input_shape (tuple): (SEQUENCE_LENGTH, features_per_frame)
        num_classes (int): ë¶„ë¥˜í•  í´ë˜ìŠ¤ ê°œìˆ˜
    """
    log_message(f"ëª¨ë¸ Input Shape: {input_shape}, Output Classes: {num_classes}")
    
    model = Sequential([
        Conv1D(128, 5, activation='relu', input_shape=input_shape),
        BatchNormalization(),
        MaxPooling1D(2),
        Dropout(0.3),

        Bidirectional(LSTM(128, return_sequences=True, dropout=0.3)),
        Bidirectional(LSTM(64, return_sequences=False, dropout=0.3)),
        Dropout(0.3),

        Dense(128, activation='relu'),
        Dropout(0.3),
        Dense(num_classes, activation='softmax')
    ])
    
    # ğŸ’¡ model.summary()ë¥¼ ì¶œë ¥í•˜ê¸° ì „ì— ëª…ì‹œì ìœ¼ë¡œ ë¹Œë“œ
    try:
        model.build(input_shape=(None, *input_shape))
        log_message("ëª¨ë¸ ë¹Œë“œ ì™„ë£Œ.")
    except Exception as e:
        log_message(f"ê²½ê³ : ëª¨ë¸ ê°•ì œ ë¹Œë“œ ì‹¤íŒ¨. {repr(e)}")


    return model
