import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Bidirectional, BatchNormalization
from sign_language_recognition.train.utils import log_message

def build_lstm_model(input_shape: tuple, num_classes: int) -> tf.keras.Model:
    """
    ìš©ëŸ‰ì„ 4ë°° í™•ì¥í•˜ê³  ë“œë¡­ì•„ì›ƒì„ ì™„í™”í•œ CNN-BiLSTM ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.
    (2,737ê°œ í´ë˜ìŠ¤ ë¯¸ë‹¬ í•™ìŠµ í•´ì†Œë¥¼ ìœ„í•œ ìµœì¢… êµ¬ì¡°)

    Args:
        input_shape (tuple): (SEQUENCE_LENGTH, features_per_frame)
        num_classes (int): ë¶„ë¥˜í•  í´ë˜ìŠ¤ ê°œìˆ˜
    """
    log_message(f"ëª¨ë¸ Input Shape: {input_shape}, Output Classes: {num_classes}")
    
    model = Sequential([
        # ğŸ’¡ Conv1D í•„í„° ìˆ˜ í™•ì¥: 128 -> 256
        Conv1D(filters=256, kernel_size=5, activation='relu', input_shape=input_shape),
        BatchNormalization(),
        MaxPooling1D(pool_size=2),
        Dropout(0.2), # ê·œì œ ì™„í™”

        # ğŸ’¡ Bidirectional LSTM ìœ ë‹› ìˆ˜ í™•ì¥: 128 -> 256
        Bidirectional(LSTM(256, return_sequences=True, dropout=0.2)),
        
        # ğŸ’¡ Bidirectional LSTM ìœ ë‹› ìˆ˜ í™•ì¥: 128 -> 256
        Bidirectional(LSTM(256, return_sequences=False, dropout=0.2)), 
        Dropout(0.2), # ê·œì œ ì™„í™”

        # ğŸ’¡ Dense ê³„ì¸µ ìœ ë‹› ìˆ˜ í™•ì¥: 128 -> 256
        Dense(256, activation='relu'),
        Dropout(0.2), # ê·œì œ ì™„í™”
        
        # ìµœì¢… ì¶œë ¥ ê³„ì¸µ
        Dense(num_classes, activation='softmax')
    ])
    
    # ëª¨ë¸ ë¹Œë“œ ë° ìš”ì•½
    try:
        model.build(input_shape=(None, *input_shape))
        log_message("ëª¨ë¸ ë¹Œë“œ ì™„ë£Œ.")
    except Exception as e:
        log_message(f"ê²½ê³ : ëª¨ë¸ ê°•ì œ ë¹Œë“œ ì‹¤íŒ¨. {repr(e)}")


    return model
