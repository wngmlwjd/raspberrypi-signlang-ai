import numpy as np
import csv
import json
from pathlib import Path
from sklearn.preprocessing import LabelEncoder
from typing import Tuple, Optional, Set, Dict, Any, List
from collections import defaultdict
import os 
import time # time ëª¨ë“ˆ ì¶”ê°€

# utils.pyì—ì„œ ì •ì˜ëœ ê²½ë¡œ, ìƒìˆ˜ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ import
from sign_language_recognition.train.utils import ( 
    log_message, BASE_DIR, PROCESSED_DIR,
    TRAIN_MANIFEST_PATH, TRAIN_X_NPY_PATH, TRAIN_Y_NPY_PATH, ENCODER_PATH,
    VAL_MANIFEST_PATH, VAL_X_NPY_PATH, VAL_Y_NPY_PATH,
    PROCESSED_MANIFEST_TRAIN, PROCESSED_MANIFEST_VAL,
    SEQUENCE_LENGTH, SEQUENCE_STEP, MAX_HANDS, pad_landmark_array
)

def load_processed_manifest_keys(path: Path) -> Set[str]:
    """ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ë‹¨ê³„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ ì™„ë£Œëœ í•­ëª©ì˜ ê³ ìœ  í‚¤ (signer/video_name)ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not path.exists():
        return set()
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return set(line.strip() for line in f if line.strip())
    except Exception as e:
        log_message(f"ê²½ê³ : ì²˜ë¦¬ ì™„ë£Œ í‚¤ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({path.name}): {e}")
        return set()

def load_sequences_from_manifest(
    manifest_path: Path, 
    base_dir: Path, 
    seq_len: int, 
    seq_step: int,
    max_hands: int,
    # âœ… ì¦ë¶„ ë¡œë”©ì„ ìœ„í•œ ìƒˆë¡œìš´ ì¸ì
    keys_to_process: Optional[Set[str]] = None 
) -> Tuple[np.ndarray, np.ndarray, Set[str]]:
    """
    manifest.csv íŒŒì¼ì„ ì½ê³ , 'keys_to_process'ì— í•´ë‹¹í•˜ëŠ” í•­ëª©ë§Œ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
    keys_to_processê°€ Noneì´ë©´ ì „ì²´ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    sequences = []
    labels = []
    
    # ... (ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸, ë¡œë“œ, í—¤ë” ë° ì—”íŠ¸ë¦¬ ê°œìˆ˜ í™•ì¸ ë¡œì§ ìœ ì§€) ...
    if not manifest_path.exists():
        log_message(f"ì˜¤ë¥˜: ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {manifest_path.absolute()}")
        return np.array([]), np.array([]), set()

    log_message(f"ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ ì¤‘: {manifest_path.name}")
    log_message(f"ì‹œí€€ìŠ¤ ì„¤ì •: ê¸¸ì´={seq_len} í”„ë ˆì„, ìŠ¤í…(ì˜¤ë²„ë©)={seq_step} í”„ë ˆì„") 
    
    manifest_entries = []
    with open(manifest_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        manifest_entries = list(reader)

    log_message(f"ì´ {len(manifest_entries)}ê°œì˜ ë°ì´í„° í•­ëª© ë°œê²¬.")
    unique_labels = set()
    
    entries_to_process_count = 0
    if keys_to_process is not None:
        entries_to_process_count = len(keys_to_process)
        log_message(f"âœ… ì¦ë¶„ ì²˜ë¦¬ ëª¨ë“œ: ì²˜ë¦¬í•  ìƒˆë¡œìš´ í•­ëª© í‚¤ {entries_to_process_count}ê°œ.")
    
    
    for idx, entry in enumerate(manifest_entries):
        unique_key = f"{entry['signer_id']}/{entry['original_video_name']}"
        
        # âœ… ì¦ë¶„ ë¡œë”©: ì²˜ë¦¬í•  í‚¤ ëª©ë¡ì— í¬í•¨ëœ í•­ëª©ë§Œ ì²˜ë¦¬
        if keys_to_process is not None and unique_key not in keys_to_process:
            continue

        relative_path = Path(entry['landmark_folder_relative_path'])
        # ì°¸ê³ : base_dirì€ './dataset'ì´ë¯€ë¡œ, ì „ì²´ ê²½ë¡œë¥¼ ì¡°í•©í•©ë‹ˆë‹¤.
        npy_data_dir = base_dir / relative_path 
        
        # ... (ë¡œê·¸ ë° ë¡œë“œ ë¡œì§ ìœ ì§€) ...
        # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í•­ëª©ì´ ì¦ë¶„ í•­ëª©ì¼ ê²½ìš°ì—ë§Œ ì§„í–‰ ìƒí™©ì„ ë¡œê·¸ì— ìì£¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        if (keys_to_process is None) and ((idx + 1) % 100 == 0 or idx == 0 or idx == len(manifest_entries) - 1):
             log_message(f"[{idx+1}/{len(manifest_entries)}] ë¡œë“œ ì¤‘: ë¼ë²¨='{entry['word_label']}', ê²½ë¡œ={relative_path}")
        elif keys_to_process is not None:
            # ì¦ë¶„ ëª¨ë“œì—ì„œëŠ” ì²˜ë¦¬ë˜ëŠ” í•­ëª©ë§Œ ì¹´ìš´íŠ¸í•˜ê³  ë¡œê·¸ë¥¼ ì°ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.
            current_processed_idx = len(labels) 
            if current_processed_idx % 10 == 0:
                 log_message(f"[ì¦ë¶„ {current_processed_idx}/{entries_to_process_count}] ë¡œë“œ ì¤‘: ë¼ë²¨='{entry['word_label']}'")

        if not npy_data_dir.is_dir():
            log_message(f"ê²½ê³ : ëœë“œë§ˆí¬ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ê±´ë„ˆëœë‹ˆë‹¤: {npy_data_dir.name}")
            continue
            
        npy_files = sorted(list(npy_data_dir.glob('*.npy')))
        current_files = npy_files
        
        for i in range(0, len(current_files) - seq_len + 1, seq_step): 
            seq_frames = []
            files_slice = current_files[i:i + seq_len]

            for npy_file in files_slice:
                try:
                    lm = np.load(npy_file, allow_pickle=True)
                    padded_lm = pad_landmark_array(lm) 
                    seq_frames.append(padded_lm.flatten())
                except Exception as e:
                    log_message(f"ê²½ê³ : NPY íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({npy_file.name}, ì‹œí€€ìŠ¤ ì¸ë±ìŠ¤ {i}): {repr(e)}")
                    continue

            if len(seq_frames) == seq_len:
                sequences.append(np.array(seq_frames))
                labels.append(entry['word_label'])
                unique_labels.add(entry['word_label'])
                
    log_message(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ. ì´ ì‹œí€€ìŠ¤ ìˆ˜: {len(sequences)}, ì´ ë¼ë²¨ ìˆ˜: {len(unique_labels)}")
    return np.array(sequences), np.array(labels), unique_labels


def _load_and_preprocess_single_dataset(
    data_type: str, # 'train' ë˜ëŠ” 'val'
    manifest_path: Path,
    x_npy_path: Path,
    y_npy_path: Path,
    processed_manifest_keys_path: Path, # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì‹œ ì‚¬ìš©ëœ ì²˜ë¦¬ ì™„ë£Œ í•­ëª© ê¸°ë¡
    label_encoder: Optional[LabelEncoder] = None,
    force_reprocess: bool = False
) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[LabelEncoder]]:
    """
    ë‹¨ì¼ ë°ì´í„°ì…‹ (í›ˆë ¨ ë˜ëŠ” ê²€ì¦)ì„ ë¡œë“œí•˜ê±°ë‚˜ manifestë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±/ì¦ë¶„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    log_message(f"--- [{data_type.upper()}] ë°ì´í„°ì…‹ ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œì‘ ---")
    
    # Manifestì˜ ëª¨ë“  í•­ëª© í‚¤ë¥¼ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def get_all_manifest_keys(m_path: Path) -> Set[str]:
        keys = set()
        if not m_path.exists():
            return keys
        with open(m_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for entry in reader:
                keys.add(f"{entry['signer_id']}/{entry['original_video_name']}")
        return keys

    X_old, Y_old = None, None
    is_incremental_mode = False
    
    # --------------------- 1. ê¸°ì¡´ NPY íŒŒì¼ ë¡œë“œ ë° ì¦ë¶„/ì¬ì²˜ë¦¬ ì—¬ë¶€ íŒë‹¨ ---------------------
    
    if x_npy_path.exists() and y_npy_path.exists() and not force_reprocess:
        try:
            # 1-1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹œë„
            # mmap_mode='r'ì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì ˆì•½í•˜ê³  íŒŒì¼ì—ì„œ ì§ì ‘ ì½ìŠµë‹ˆë‹¤.
            X_old = np.load(x_npy_path, mmap_mode='r') 
            Y_old = np.load(y_npy_path, mmap_mode='r') 
            log_message(f"ê¸°ì¡´ NPY ë°ì´í„° ë¡œë“œ ì„±ê³µ. Shape: X={X_old.shape}, Y={Y_old.shape}")
            
            # 1-2. ë§¤ë‹ˆí˜ìŠ¤íŠ¸ í‚¤ íŒŒì¼ê³¼ ë¹„êµí•˜ì—¬ ì¦ë¶„ ì²˜ë¦¬ í•„ìš”ì„± íŒë‹¨
            
            # **A. NPY íŒŒì¼ì´ ìµœì‹ ì¸ì§€ í™•ì¸** (ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ë³€ê²½ ì—¬ë¶€)
            manifest_time = os.path.getmtime(manifest_path) if manifest_path.exists() else 0
            npy_time = os.path.getmtime(x_npy_path)
            
            if manifest_time > npy_time:
                # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ê°€ NPYë³´ë‹¤ ìµœì‹ ì¸ ê²½ìš°: ì¦ë¶„ ë˜ëŠ” ì „ì²´ ì¬ì²˜ë¦¬ í•„ìš”
                
                # **B. ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì˜ ëª¨ë“  í‚¤ì™€ ì´ì „ì— ì²˜ë¦¬ëœ í‚¤ ë¹„êµ**
                all_keys_in_manifest = get_all_manifest_keys(manifest_path)
                processed_keys_in_txt = load_processed_manifest_keys(processed_manifest_keys_path)
                
                # NPYê°€ ìƒì„±ëœ ì´í›„ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì— ì¶”ê°€ëœ í‚¤ (ìƒˆë¡œìš´ ë¹„ë””ì˜¤ í•­ëª©)
                new_keys_to_process = all_keys_in_manifest - processed_keys_in_txt
                
                if not new_keys_to_process:
                    log_message("âš ï¸ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ëŠ” ìµœì‹ ì´ì§€ë§Œ, NPY ìƒì„± ì´í›„ì— ì¶”ê°€ëœ ìƒˆ í•­ëª© í‚¤ê°€ ì—†ì–´ ì¦ë¶„ ì²˜ë¦¬ ê±´ë„ˆëœ€.")
                    # NPY íŒŒì¼ ìˆ˜ì • ì‹œê°„ì„ Manifestì™€ ë™ê¸°í™” (ë‹¤ìŒë²ˆ ì‹¤í–‰ ì‹œ ë‹¤ì‹œ ê²€ì‚¬í•˜ì§€ ì•Šë„ë¡)
                    os.utime(x_npy_path, (time.time(), time.path.getmtime(manifest_path))) 
                    return X_old, Y_old, label_encoder

                log_message(f"âœ… ì¦ë¶„ ì²˜ë¦¬ ì‹œì‘: ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì— {len(new_keys_to_process)}ê°œì˜ ìƒˆ í•­ëª©ì´ ì¶”ê°€ë¨.")
                is_incremental_mode = True
                
            else:
                log_message("NPY íŒŒì¼ì´ ìµœì‹ ì´ê±°ë‚˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì™€ ë™ê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì²˜ë¦¬ ê±´ë„ˆëœ€.")
                return X_old, Y_old, label_encoder
                
        except Exception as e:
            log_message(f"ê²½ê³ : NPY íŒŒì¼ ë¡œë“œ ë˜ëŠ” ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({repr(e)}). ì „ì²´ ì¬ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            force_reprocess = True

    # --------------------- 2. ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬ (ì¬ì²˜ë¦¬ ë˜ëŠ” ì¦ë¶„) ---------------------
    
    # 2-1. ì¬ì²˜ë¦¬ ëª¨ë“œ ê²°ì •
    if force_reprocess:
        log_message("ê°•ì œ ì¬ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™”. ì „ì²´ manifestë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        x_npy_path.unlink(missing_ok=True)
        y_npy_path.unlink(missing_ok=True)
        X_old, Y_old = None, None # np.array([]) ëŒ€ì‹  Noneì„ ì‚¬ìš©í•˜ì—¬ ëª…í™•íˆ êµ¬ë¶„
        keys_to_process = None # ì „ì²´ manifest ì²˜ë¦¬
        
    elif is_incremental_mode:
        log_message("ì¦ë¶„ ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™”. ìƒˆ í•­ëª©ë§Œ ë¡œë“œí•©ë‹ˆë‹¤.")
        # ì´ì „ì— ì°¾ì€ new_keys_to_process ì‚¬ìš©
        keys_to_process = new_keys_to_process 
        
    else:
        # NPY íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°, ì „ì²´ ì¬ì²˜ë¦¬
        log_message("ì‚¬ì „ ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ manifestë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        keys_to_process = None


    # 2-2. raw ë°ì´í„° ë¡œë“œ (ìƒˆ ë°ì´í„° ë˜ëŠ” ì „ì²´ ë°ì´í„°)
    x_new_raw, y_new_raw_labels, _ = load_sequences_from_manifest(
        manifest_path=manifest_path, 
        base_dir=BASE_DIR, 
        seq_len=SEQUENCE_LENGTH, 
        seq_step=SEQUENCE_STEP,
        max_hands=MAX_HANDS,
        keys_to_process=keys_to_process # ì¦ë¶„ ëª¨ë“œ ì‹œ, ìƒˆ í‚¤ë§Œ ì „ë‹¬
    )
    
    if x_new_raw.size == 0 and X_old is None:
        log_message("ì˜¤ë¥˜: ë¡œë“œí•  ì‹œí€€ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return None, None, label_encoder

    # 2-3. ë¼ë²¨ ì¸ì½”ë”© ë° ìµœì¢… ë³‘í•©
    X_final, Y_final = x_new_raw, None

    if X_old is not None:
        # ğŸŸ¢ ì¦ë¶„ ëª¨ë“œ
        if label_encoder is None:
             log_message("ì¹˜ëª…ì  ì˜¤ë¥˜: ì¦ë¶„ ëª¨ë“œì¸ë° LabelEncoderê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
             return None, None, label_encoder
             
        try:
            Y_new_encoded = label_encoder.transform(y_new_raw_labels)
        except ValueError as e:
            log_message(f"ì¹˜ëª…ì  ì˜¤ë¥˜: ì¦ë¶„ ë°ì´í„°ì— í›ˆë ¨ ë°ì´í„°ì— ì—†ëŠ” í´ë˜ìŠ¤ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. {repr(e)}")
            return None, None, label_encoder
        
        # ë°ì´í„° ë³‘í•© (ê¸°ì¡´ + ì‹ ê·œ)
        X_final = np.concatenate((X_old, x_new_raw), axis=0)
        Y_final = np.concatenate((Y_old, Y_new_encoded), axis=0)
        
        log_message(f"ì¦ë¶„ ë°ì´í„° ë³‘í•© ì™„ë£Œ. ìµœì¢… Shape: X={X_final.shape}, Y={Y_final.shape}")
        
        # X_oldì™€ Y_oldê°€ mmap_mode='r'ë¡œ ë¡œë“œë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë©”ëª¨ë¦¬ì— ë³µì‚¬í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
        X_final = X_final.copy()
        Y_final = Y_final.copy()

    else:
        # ğŸ”´ ì „ì²´ ì¬ì²˜ë¦¬ (force_reprocess=True ë˜ëŠ” NPY íŒŒì¼ì´ ì—†ë˜ ê²½ìš°)
        if data_type == 'train':
            # í›ˆë ¨ ë°ì´í„°ì¸ ê²½ìš°ì—ë§Œ ì¸ì½”ë”ë¥¼ ìƒˆë¡œ fit
            if label_encoder is None:
                label_encoder = LabelEncoder()
                Y_final = label_encoder.fit_transform(y_new_raw_labels) 
                log_message(f"[{data_type.upper()}] ìƒˆë¡œìš´ LabelEncoderë¥¼ ìƒì„±í•˜ê³  fití–ˆìŠµë‹ˆë‹¤. í´ë˜ìŠ¤ ìˆ˜={len(label_encoder.classes_)}")
            else:
                # force_reprocessê°€ Trueì´ì§€ë§Œ ì™¸ë¶€ì—ì„œ encoderë¥¼ ì „ë‹¬ë°›ì€ ê²½ìš°
                Y_final = label_encoder.transform(y_new_raw_labels)
                log_message(f"[{data_type.upper()}] ê¸°ì¡´ LabelEncoderë¥¼ ì‚¬ìš©í•˜ì—¬ transformí–ˆìŠµë‹ˆë‹¤.")
        elif data_type == 'val':
            # ê²€ì¦ ë°ì´í„°ì¸ ê²½ìš° í›ˆë ¨ ë°ì´í„°ì—ì„œ ìƒì„±ëœ ì¸ì½”ë”ë¥¼ ì‚¬ìš©
            if label_encoder is not None:
                try:
                    Y_final = label_encoder.transform(y_new_raw_labels)
                    log_message(f"[{data_type.upper()}] ê¸°ì¡´ LabelEncoderë¥¼ ì‚¬ìš©í•˜ì—¬ transformí–ˆìŠµë‹ˆë‹¤.")
                except ValueError as e:
                    log_message(f"ì¹˜ëª…ì  ì˜¤ë¥˜: ê²€ì¦ ë°ì´í„°ì— í›ˆë ¨ ë°ì´í„°ì— ì—†ëŠ” í´ë˜ìŠ¤ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. {repr(e)}")
                    return None, None, label_encoder
            else:
                 log_message("ì¹˜ëª…ì  ì˜¤ë¥˜: ê²€ì¦ ë°ì´í„°ëŠ” í›ˆë ¨ ì¸ì½”ë”ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                 return None, None, label_encoder
        
        X_final = x_new_raw
        # Y_finalì€ ìœ„ì—ì„œ ì´ë¯¸ ê³„ì‚°ë¨

    # 2-4. ì €ì¥ (NPY íŒŒì¼ ë®ì–´ì“°ê¸°)
    os.makedirs(x_npy_path.parent, exist_ok=True)
    
    np.save(x_npy_path, X_final)
    np.save(y_npy_path, Y_final) 
    
    # NPY ì €ì¥ í›„, ë§¤ë‹ˆí˜ìŠ¤íŠ¸ í‚¤ íŒŒì¼ë„ ì—…ë°ì´íŠ¸ (ì „ì²´ í‚¤ë¡œ ë®ì–´ì“°ê¸°)
    if is_incremental_mode:
        # ğŸŒŸ ìƒˆë¡œ ì²˜ë¦¬ëœ í‚¤ë§Œ ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€ ('a' ëª¨ë“œ)
        with open(processed_manifest_keys_path, 'a', encoding='utf-8') as f:
            for key in new_keys_to_process:
                f.write(key + '\n')
        log_message(f"âœ… ì²˜ë¦¬ ì™„ë£Œ í‚¤ íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {processed_manifest_keys_path.name} ({len(new_keys_to_process)}ê°œ ì¶”ê°€)")
        
        # NPY íŒŒì¼ì˜ ìˆ˜ì • ì‹œê°„ì„ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì™€ ë™ê¸°í™”
        os.utime(x_npy_path, (time.time(), os.path.getmtime(manifest_path)))
        os.utime(y_npy_path, (time.time(), os.path.getmtime(manifest_path)))

    elif force_reprocess and X_final.size > 0:
        # ì „ì²´ ì¬ì²˜ë¦¬ í›„ì—ëŠ” í˜„ì¬ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì˜ ëª¨ë“  í‚¤ë¡œ íŒŒì¼ ì¬ì‘ì„± ('w' ëª¨ë“œ)
        all_keys_in_manifest = get_all_manifest_keys(manifest_path)
        with open(processed_manifest_keys_path, 'w', encoding='utf-8') as f:
            for key in all_keys_in_manifest:
                f.write(key + '\n')
        log_message(f"âœ… ì „ì²´ ì¬ì²˜ë¦¬ í›„ ì²˜ë¦¬ ì™„ë£Œ í‚¤ íŒŒì¼ ì¬ì‘ì„± ì™„ë£Œ: {processed_manifest_keys_path.name}")
        # NPY íŒŒì¼ì˜ ìˆ˜ì • ì‹œê°„ì„ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì™€ ë™ê¸°í™”
        os.utime(x_npy_path, (time.time(), os.path.getmtime(manifest_path)))
        os.utime(y_npy_path, (time.time(), os.path.getmtime(manifest_path)))


    log_message(f"[{data_type.upper()}] ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: {x_npy_path.name}, {y_npy_path.name}")
    log_message(f"[{data_type.upper()}] ìµœì¢… ìƒì„±ëœ ë°ì´í„° shape: X={X_final.shape}, Y={Y_final.shape}")
    
    return X_final, Y_final, label_encoder


def prepare_and_load_datasets(
    force_reprocess: bool = False
) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[LabelEncoder]]:
    """
    ì „ì²´ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì—¬ í›ˆë ¨ ë° ê²€ì¦ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•˜ê³  ë¡œë“œí•©ë‹ˆë‹¤.
    """
    log_message("\n" + "#" * 50)
    log_message("### ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ###")
    log_message(f"ê°•ì œ ì¬ì²˜ë¦¬ ëª¨ë“œ (FORCE_REPROCESS): {force_reprocess}")
    
    # 0. í´ë” ìƒì„± í™•ì¸
    os.makedirs(PROCESSED_DIR, exist_ok=True)
    os.makedirs(ENCODER_PATH.parent, exist_ok=True)
    
    # 1. ì´ˆê¸°í™” (force_reprocess ì¸ìˆ˜ë¥¼ ì‚¬ìš©)
    if force_reprocess:
        log_message("ê°•ì œ ì¬ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™”: ê¸°ì¡´ NPY ë° ì¸ì½”ë” íŒŒì¼ ì´ˆê¸°í™”.")
        TRAIN_X_NPY_PATH.unlink(missing_ok=True)
        TRAIN_Y_NPY_PATH.unlink(missing_ok=True)
        VAL_X_NPY_PATH.unlink(missing_ok=True)
        VAL_Y_NPY_PATH.unlink(missing_ok=True)
        ENCODER_PATH.unlink(missing_ok=True)
        # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì²˜ë¦¬ ê¸°ë¡ íŒŒì¼ë„ ì´ˆê¸°í™”
        PROCESSED_MANIFEST_TRAIN.unlink(missing_ok=True)
        PROCESSED_MANIFEST_VAL.unlink(missing_ok=True)

    
    # 2. í›ˆë ¨ ë°ì´í„° ì²˜ë¦¬ 
    X_train, Y_train, encoder = _load_and_preprocess_single_dataset(
        data_type='train',
        manifest_path=TRAIN_MANIFEST_PATH,
        x_npy_path=TRAIN_X_NPY_PATH,
        y_npy_path=TRAIN_Y_NPY_PATH,
        processed_manifest_keys_path=PROCESSED_MANIFEST_TRAIN, # âœ… ì²˜ë¦¬ í‚¤ ê²½ë¡œ ì „ë‹¬
        label_encoder=None,
        force_reprocess=force_reprocess
    )
    
    # 3. ì¸ì½”ë” ì €ì¥ ë° ë¡œë“œ
    if encoder is not None:
        # NPY íŒŒì¼ì´ ìƒˆë¡œ ìƒì„±ëœ ê²½ìš°ì—ë§Œ ì¸ì½”ë”ë¥¼ ì €ì¥
        if not ENCODER_PATH.exists() or force_reprocess: 
            with open(ENCODER_PATH, 'w') as f:
                json.dump({'classes': list(encoder.classes_)}, f)
            log_message(f"ìµœì¢… LabelEncoder ì €ì¥ ì™„ë£Œ: {ENCODER_PATH.name}, í´ë˜ìŠ¤ ìˆ˜={len(encoder.classes_)}")
    elif ENCODER_PATH.exists():
        # NPY íŒŒì¼ì„ ì¬ì²˜ë¦¬í•˜ì§€ ì•Šê³  ê¸°ì¡´ íŒŒì¼ì„ ë¡œë“œí•œ ê²½ìš°, ì¸ì½”ë”ë¥¼ ë¡œë“œí•´ì•¼ í•¨
        try:
            with open(ENCODER_PATH, 'r') as f:
                classes = json.load(f)['classes']
            encoder = LabelEncoder()
            encoder.classes_ = np.array(classes)
            log_message(f"ê¸°ì¡´ LabelEncoder ë¡œë“œ ì™„ë£Œ. í´ë˜ìŠ¤ ìˆ˜={len(encoder.classes_)}")
        except Exception as e:
            log_message(f"ê²½ê³ : ê¸°ì¡´ ì¸ì½”ë” ë¡œë“œ ì‹¤íŒ¨ ({repr(e)}). ê²€ì¦ ë°ì´í„° ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            encoder = None


    # 4. ê²€ì¦ ë°ì´í„° ì²˜ë¦¬ 
    X_val, Y_val = None, None
    if encoder is not None:
        X_val, Y_val, _ = _load_and_preprocess_single_dataset(
            data_type='val',
            manifest_path=VAL_MANIFEST_PATH,
            x_npy_path=VAL_X_NPY_PATH,
            y_npy_path=VAL_Y_NPY_PATH,
            processed_manifest_keys_path=PROCESSED_MANIFEST_VAL, # âœ… ì²˜ë¦¬ í‚¤ ê²½ë¡œ ì „ë‹¬
            label_encoder=encoder, # í›ˆë ¨ ë°ì´í„° ì¸ì½”ë” ì „ë‹¬
            force_reprocess=force_reprocess
        )
    else:
        log_message("LabelEncoderê°€ ì—†ìœ¼ë¯€ë¡œ ê²€ì¦ ë°ì´í„° ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    
    # 5. ìµœì¢… ìš”ì•½
    log_message("\n" + "="*50)
    log_message("ìµœì¢… ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ìš”ì•½")
    if X_train is not None:
        log_message(f"í›ˆë ¨ ë°ì´í„° (X_train): {X_train.shape}")
    if X_val is not None:
        log_message(f"ê²€ì¦ ë°ì´í„° (X_val): {X_val.shape}")
    if encoder is not None:
        log_message(f"ì´ í´ë˜ìŠ¤ ìˆ˜: {len(encoder.classes_)}")
    log_message("### ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ###")
    log_message("#" * 50)
    
    return X_train, Y_train, X_val, Y_val, encoder
