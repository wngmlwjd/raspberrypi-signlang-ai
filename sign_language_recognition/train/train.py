import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
import tensorflow.keras.metrics as metrics
from sklearn.model_selection import train_test_split
import numpy as np
import re
from pathlib import Path
from sklearn.preprocessing import LabelEncoder

# í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ê²½ë¡œ ìˆ˜ì •
from sign_language_recognition.train.utils import log_message, SEQUENCE_LENGTH, MODEL_DIR
from sign_language_recognition.train.preprocess import prepare_and_load_datasets
from sign_language_recognition.models.model import build_lstm_model

def get_latest_version(model_dir: Path, base_model_name: str):
    """ëª¨ë¸ ë²„ì „ í™•ì¸ (ìƒëµëœ ë¡œì§ ëŒ€ì‹  ì‹¤ì œ ë¡œì§ì„ í¬í•¨)"""
    if not model_dir.exists():
        return 0
    pattern = re.compile(rf"{re.escape(base_model_name)}_v(\d+)\.h5$")
    versions = []
    for file in model_dir.iterdir():
        match = pattern.match(file.name)
        if match:
            versions.append(int(match.group(1)))
    return max(versions) if versions else 0

def train_sign_language_model(epochs: int = 100, batch_size: int = 256, validation_split: float = 0.5, retrain: bool = False):
    """
    ìˆ˜ì–´ ì¸ì‹ ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•œ ë©”ì¸ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Args:
        epochs: í›ˆë ¨ ì—í¬í¬ ìˆ˜
        batch_size: ë°°ì¹˜ í¬ê¸° (32 -> 256ìœ¼ë¡œ ìƒí–¥ ì¡°ì •)
        validation_split: ë¡œë“œëœ 'ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°(X_val)'ë¥¼ Keras 'ê²€ì¦'ê³¼ 'ìµœì¢… í…ŒìŠ¤íŠ¸'ë¡œ ë‚˜ëˆŒ ë¹„ìœ¨.
        retrain: Trueë©´ ìƒˆ ëª¨ë¸ ìƒì„± ë° ë²„ì „ ì—…, Falseë©´ ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì™€ ì¶”ê°€ í•™ìŠµ
    """
    base_model_name = "best_sign_model"
    MODEL_DIR.mkdir(parents=True, exist_ok=True)

    log_message("--- ìˆ˜ì–´ ì¸ì‹ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ---")

    # 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ 
    X_train, Y_train, X_test_full, Y_test_full, encoder = prepare_and_load_datasets(force_reprocess=False)
    
    if X_train is not None and X_train.size > 0:
        min_val = np.min(X_train)
        max_val = np.max(X_train)
        mean_val = np.mean(X_train)
        std_val = np.std(X_train)

        print("\n[ë°ì´í„° ì •ê·œí™” í™•ì¸ ê²°ê³¼]")
        print(f"ìµœì†Œê°’ (Min): {min_val:.4f}")
        print(f"ìµœëŒ€ê°’ (Max): {max_val:.4f}")
        print(f"í‰ê·  (Mean): {mean_val:.4f}")
        print(f"í‘œì¤€í¸ì°¨ (Std Dev): {std_val:.4f}")
        print("----------------------------\n")
    else:
        print("X_train ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    if X_train is None or encoder is None:
        log_message("í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” LabelEncoder ëˆ„ë½. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    num_classes = len(encoder.classes_)
    
    # 2. ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° í’€ (X_test_full)ì„ Keras ê²€ì¦ìš©ê³¼ ìµœì¢… í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• 
    log_message(f"ë¡œë“œëœ ì „ì²´ í›ˆë ¨ ë°ì´í„° í¬ê¸°: {X_train.shape[0]} (ì „ë¶€ í›ˆë ¨ì— ì‚¬ìš©)")
    log_message(f"ë¡œë“œëœ ê²€ì¦/í…ŒìŠ¤íŠ¸ í’€ í¬ê¸°: {X_test_full.shape[0]}")
    log_message(f"ê²€ì¦/í…ŒìŠ¤íŠ¸ í’€ ë¶„í•  ë¹„ìœ¨ (Keras ê²€ì¦ìš©:ìµœì¢… í…ŒìŠ¤íŠ¸ìš©): {validation_split:.2f}:{1.0 - validation_split:.2f}")

    if X_test_full.shape[0] > 0 and validation_split > 0 and validation_split < 1.0:
        X_test_final, X_val_keras, Y_test_final, Y_val_keras = train_test_split(
            X_test_full, Y_test_full, test_size=validation_split, 
            shuffle=True, random_state=42, stratify=Y_test_full
        )
        validation_data_tuple = (X_val_keras, Y_val_keras)
    else:
        X_test_final, Y_test_final = X_test_full, Y_test_full
        X_val_keras, Y_val_keras = None, None
        validation_data_tuple = None

    # 3. ë°ì´í„° í¬ê¸° í™•ì¸
    if X_train.shape[0] == 0:
        log_message("í›ˆë ¨ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
        
    log_message(f"ì‹¤ì œ í›ˆë ¨ ë°ì´í„° í¬ê¸°: {X_train.shape[0]}")
    if X_val_keras is not None:
        log_message(f"Keras ê²€ì¦ ë°ì´í„° í¬ê¸°: {X_val_keras.shape[0]}")
    log_message(f"ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸° (í›ˆë ¨ì— ì‚¬ìš©ë˜ì§€ ì•ŠìŒ): {X_test_final.shape[0]}")

    input_shape = (SEQUENCE_LENGTH, X_train.shape[2])
    model = None
    initial_epoch = 0

    latest_version = get_latest_version(MODEL_DIR, base_model_name)
    if retrain:
        new_version = latest_version + 1
        versioned_model_path = MODEL_DIR / f"{base_model_name}_v{new_version}.h5"
        log_message(f"retrain=True -> ìƒˆ ëª¨ë¸ ë²„ì „ {new_version} ìƒì„±: {versioned_model_path.name}")
        model = build_lstm_model(input_shape=input_shape, num_classes=num_classes)
        save_path = versioned_model_path
    else:
        if latest_version > 0:
            latest_model_path = MODEL_DIR / f"{base_model_name}_v{latest_version}.h5"
            try:
                # ğŸ’¡ ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹œ, ì´ì „ í•™ìŠµ ê¸°ë¡ì„ í™•ì¸í•˜ê³  initial_epoch ì„¤ì • (ì¬ê°œ í•™ìŠµ ì‹œ í•„ìš”)
                # ë‹¤ë§Œ, ë¡œê·¸ì— ì´ˆê¸° ì—í¬í¬ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ê°€ì •í•˜ê³ , ìƒˆ ëª¨ë¸ë¡œ ë®ì–´ì“°ì§€ ì•Šë„ë¡ ê²½ë¡œë§Œ ì‚¬ìš©
                model = tf.keras.models.load_model(str(latest_model_path), compile=False)
                log_message(f"ê¸°ì¡´ ëª¨ë¸ ë²„ì „ {latest_version} ë¡œë“œ: {latest_model_path.name}")
                save_path = latest_model_path
            except Exception as e:
                log_message(f"ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨({repr(e)}), ìƒˆ ëª¨ë¸ ìƒì„±")
                model = build_lstm_model(input_shape=input_shape, num_classes=num_classes)
                save_path = MODEL_DIR / f"{base_model_name}_v1.h5"
        else:
            log_message("ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ -> ìƒˆ ëª¨ë¸ ìƒì„±")
            model = build_lstm_model(input_shape=input_shape, num_classes=num_classes)
            save_path = MODEL_DIR / f"{base_model_name}_v1.h5"

    # ğŸ’¡ í•™ìŠµë¥ ì„ 0.005ë¡œ ìƒí–¥ ì¡°ì •
    model.compile(
        optimizer=Adam(learning_rate=0.0025), # 0.001 -> 0.005ë¡œ ìƒí–¥
        loss='sparse_categorical_crossentropy',
        metrics=[
            'accuracy',
            metrics.SparseTopKCategoricalAccuracy(k=5, name='sparse_top_5_accuracy')
        ]
    )
    model.summary()

    # ì½œë°± ì„¤ì •
    monitor_metric = 'accuracy'
    if validation_data_tuple:
        # ğŸ’¡ ê²€ì¦ ë°ì´í„°ê°€ ìˆìœ¼ë©´ 'val_accuracy'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§
        monitor_metric = 'val_accuracy' 

    model_checkpoint_callback = ModelCheckpoint(
        filepath=str(save_path),
        save_weights_only=False,
        monitor=monitor_metric, # val_accuracyë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ëª¨ë¸ ì €ì¥
        mode='max',
        save_best_only=True,
        verbose=1
    )
    
    # ğŸ’¡ Early Stoppingê³¼ ReduceLROnPlateau ëª¨ë‘ 'val_accuracy'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì • (ì„±ëŠ¥ ê°œì„ ì— ì§‘ì¤‘)
    # monitor_acc = 'accuracy' if not validation_data_tuple else 'val_accuracy'
    
    early_stopping_callback = EarlyStopping(
        monitor='accuracy' if not validation_data_tuple else 'val_accuracy',
        patience=10, # 10ë²ˆ ì—í¬í¬ ë™ì•ˆ ì •í™•ë„ ê°œì„ ì´ ì—†ìœ¼ë©´ ì¤‘ë‹¨
        verbose=1,
        mode='max',
        restore_best_weights=True
    )
    
    reduce_lr_callback = ReduceLROnPlateau(
        monitor='accuracy' if not validation_data_tuple else 'val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-6,
        verbose=1,
        mode='min'
    )

    log_message(f"ëª¨ë¸ í›ˆë ¨ ì‹œì‘ (Epochs: {epochs}, Batch Size: {batch_size})")
    history = model.fit(
        X_train, Y_train,
        epochs=epochs,
        batch_size=batch_size, # ğŸ’¡ ë°°ì¹˜ ì‚¬ì´ì¦ˆ 32 -> 256ìœ¼ë¡œ ìƒí–¥ ì¡°ì •
        validation_data=validation_data_tuple, 
        callbacks=[model_checkpoint_callback, early_stopping_callback, reduce_lr_callback],
        verbose=1,
        initial_epoch=initial_epoch
    )

    log_message("--- ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ---")
    best_acc = max(history.history[monitor_metric])
    log_message(f"ìµœê³  {monitor_metric} ì •í™•ë„: {best_acc:.4f}")
    log_message(f"ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {save_path.name}")
    log_message(f"ìµœì¢… í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° (X_test_final) í¬ê¸°: {X_test_final.shape[0]}")

    # ë¡œë“œëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°(X_test_final, Y_test_final)ë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ì—¬ ìµœì¢… í‰ê°€ì— ì‚¬ìš©
    return history, X_test_final, Y_test_final, save_path